{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>34678741</td>\n",
       "      <td>R9T1FE2ZX2X04</td>\n",
       "      <td>B003V264WW</td>\n",
       "      <td>732252283</td>\n",
       "      <td>remington ac2015 t|studio salon collection pea...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Works great</td>\n",
       "      <td>Works great!</td>\n",
       "      <td>8/31/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>11599505</td>\n",
       "      <td>RE36JAD5V53PO</td>\n",
       "      <td>B0009XH6V4</td>\n",
       "      <td>670161917</td>\n",
       "      <td>andis micro turbo hair dryer</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>I love travel blow dryers because they are eas...</td>\n",
       "      <td>This dries my hair faster that bigger, more po...</td>\n",
       "      <td>8/31/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>2282190</td>\n",
       "      <td>RIDHM8B7SCCV3</td>\n",
       "      <td>B0007NZPY6</td>\n",
       "      <td>16483457</td>\n",
       "      <td>conair pro hair dryer</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Love this dryer!</td>\n",
       "      <td>8/31/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>43669858</td>\n",
       "      <td>R14QGWPCHU9LSE</td>\n",
       "      <td>B00BB8ZIW0</td>\n",
       "      <td>253917972</td>\n",
       "      <td>remington silk ceramic professional hair dryer</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>styling hair in style</td>\n",
       "      <td>8/31/2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>107098</td>\n",
       "      <td>R35BHQJHXXJD59</td>\n",
       "      <td>B003V264WW</td>\n",
       "      <td>732252283</td>\n",
       "      <td>remington ac2015 t|studio salon collection pea...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>I think's great. The cord length is perfect</td>\n",
       "      <td>I just got this last week. I think's great. Th...</td>\n",
       "      <td>8/31/2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     34678741   R9T1FE2ZX2X04  B003V264WW       732252283   \n",
       "1          US     11599505   RE36JAD5V53PO  B0009XH6V4       670161917   \n",
       "2          US      2282190   RIDHM8B7SCCV3  B0007NZPY6        16483457   \n",
       "3          US     43669858  R14QGWPCHU9LSE  B00BB8ZIW0       253917972   \n",
       "4          US       107098  R35BHQJHXXJD59  B003V264WW       732252283   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  remington ac2015 t|studio salon collection pea...           Beauty   \n",
       "1                       andis micro turbo hair dryer           Beauty   \n",
       "2                              conair pro hair dryer           Beauty   \n",
       "3     remington silk ceramic professional hair dryer           Beauty   \n",
       "4  remington ac2015 t|studio salon collection pea...           Beauty   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            5              0            0    N                 Y   \n",
       "1            4              0            0    N                 Y   \n",
       "2            5              0            1    N                 Y   \n",
       "3            5              0            0    N                 Y   \n",
       "4            4              0            0    N                 N   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0                                        Works great   \n",
       "1  I love travel blow dryers because they are eas...   \n",
       "2                                         Five Stars   \n",
       "3                                         Five Stars   \n",
       "4        I think's great. The cord length is perfect   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0                                       Works great!   8/31/2015  \n",
       "1  This dries my hair faster that bigger, more po...   8/31/2015  \n",
       "2                                   Love this dryer!   8/31/2015  \n",
       "3                              styling hair in style   8/31/2015  \n",
       "4  I just got this last week. I think's great. Th...   8/31/2015  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import string    \n",
    "\n",
    "\n",
    "tab1 = \"./hair_dryer.tsv\"\n",
    "\n",
    "df = pd.read_csv(tab1, sep='\\t', header=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_descriptor = ['wonderful', 'perfect', 'impress', 'excellent', 'awesome', 'beautiful', 'incredi', 'happy', 'attractive'\n",
    "                       'awful', 'disgusting', 'horrib', 'insane', 'miserable', 'nasty', 'outrageous', 'terri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/alphonse/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/alphonse/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/alphonse/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     /home/alphonse/nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "#import nltk resources\n",
    "resources = [\"wordnet\", \"stopwords\", \"punkt\", \\\n",
    "             \"averaged_perceptron_tagger\", \"maxent_treebank_pos_tagger\"]\n",
    "\n",
    "for resource in resources:\n",
    "    try:\n",
    "        nltk.data.find(\"tokenizers/\" + resource)\n",
    "    except LookupError:\n",
    "        nltk.download(resource)\n",
    "\n",
    "#create Lemmatizer object\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_word(tagged_token):\n",
    "    \"\"\" Returns lemmatized word given its tag\"\"\"\n",
    "    root = []\n",
    "    for token in tagged_token:\n",
    "        tag = token[1][0]\n",
    "        word = token[0]\n",
    "        if tag.startswith('J'):\n",
    "            root.append(lemma.lemmatize(word, wordnet.ADJ))\n",
    "        elif tag.startswith('V'):\n",
    "            root.append(lemma.lemmatize(word, wordnet.VERB))\n",
    "        elif tag.startswith('N'):\n",
    "            root.append(lemma.lemmatize(word, wordnet.NOUN))\n",
    "        elif tag.startswith('R'):\n",
    "            root.append(lemma.lemmatize(word, wordnet.ADV))\n",
    "        else:          \n",
    "            root.append(word)\n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_doc(document):\n",
    "    \"\"\" Tags words then returns sentence with lemmatized words\"\"\"\n",
    "    lemmatized_list = []\n",
    "    tokenized_sent = sent_tokenize(document)\n",
    "    for sentence in tokenized_sent:\n",
    "        no_punctuation = re.sub(r\"[`'\\\",.!?()]\", \" \", sentence)\n",
    "        tokenized_word = word_tokenize(no_punctuation)\n",
    "        tagged_token = pos_tag(tokenized_word)\n",
    "        lemmatized = lemmatize_word(tagged_token)\n",
    "        lemmatized_list.extend(lemmatized)\n",
    "    return \" \".join(lemmatized_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unicodedata import normalize\n",
    "\n",
    "\n",
    "\n",
    "remove_accent = lambda text: normalize(\"NFKD\", text).encode(\"ascii\", \"ignore\").decode(\"utf-8\", \"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample stop words: ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'youre', 'youve', 'youll', 'youd', 'your', 'yours'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "stop_words = [word.replace(\"\\'\", \"\") for word in stop_words]\n",
    "\n",
    "print(f\"sample stop words: {stop_words[:15]} \\n\")\n",
    "\n",
    "remove_stop_words = lambda row: \" \".join([token for token in row.split(\" \") \\\n",
    "                                          if token not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>34678741</td>\n",
       "      <td>R9T1FE2ZX2X04</td>\n",
       "      <td>B003V264WW</td>\n",
       "      <td>732252283</td>\n",
       "      <td>remington ac2015 t|studio salon collection pea...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Works great</td>\n",
       "      <td>Works great!</td>\n",
       "      <td>8/31/2015</td>\n",
       "      <td>works great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>11599505</td>\n",
       "      <td>RE36JAD5V53PO</td>\n",
       "      <td>B0009XH6V4</td>\n",
       "      <td>670161917</td>\n",
       "      <td>andis micro turbo hair dryer</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>I love travel blow dryers because they are eas...</td>\n",
       "      <td>This dries my hair faster that bigger, more po...</td>\n",
       "      <td>8/31/2015</td>\n",
       "      <td>dry hair faster big powerful model love travel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>2282190</td>\n",
       "      <td>RIDHM8B7SCCV3</td>\n",
       "      <td>B0007NZPY6</td>\n",
       "      <td>16483457</td>\n",
       "      <td>conair pro hair dryer</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Love this dryer!</td>\n",
       "      <td>8/31/2015</td>\n",
       "      <td>love dryer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>43669858</td>\n",
       "      <td>R14QGWPCHU9LSE</td>\n",
       "      <td>B00BB8ZIW0</td>\n",
       "      <td>253917972</td>\n",
       "      <td>remington silk ceramic professional hair dryer</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>styling hair in style</td>\n",
       "      <td>8/31/2015</td>\n",
       "      <td>style hair style</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>107098</td>\n",
       "      <td>R35BHQJHXXJD59</td>\n",
       "      <td>B003V264WW</td>\n",
       "      <td>732252283</td>\n",
       "      <td>remington ac2015 t|studio salon collection pea...</td>\n",
       "      <td>Beauty</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>I think's great. The cord length is perfect</td>\n",
       "      <td>I just got this last week. I think's great. Th...</td>\n",
       "      <td>8/31/2015</td>\n",
       "      <td>get last week think great cord length perfect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     34678741   R9T1FE2ZX2X04  B003V264WW       732252283   \n",
       "1          US     11599505   RE36JAD5V53PO  B0009XH6V4       670161917   \n",
       "2          US      2282190   RIDHM8B7SCCV3  B0007NZPY6        16483457   \n",
       "3          US     43669858  R14QGWPCHU9LSE  B00BB8ZIW0       253917972   \n",
       "4          US       107098  R35BHQJHXXJD59  B003V264WW       732252283   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0  remington ac2015 t|studio salon collection pea...           Beauty   \n",
       "1                       andis micro turbo hair dryer           Beauty   \n",
       "2                              conair pro hair dryer           Beauty   \n",
       "3     remington silk ceramic professional hair dryer           Beauty   \n",
       "4  remington ac2015 t|studio salon collection pea...           Beauty   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0            5              0            0    N                 Y   \n",
       "1            4              0            0    N                 Y   \n",
       "2            5              0            1    N                 Y   \n",
       "3            5              0            0    N                 Y   \n",
       "4            4              0            0    N                 N   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0                                        Works great   \n",
       "1  I love travel blow dryers because they are eas...   \n",
       "2                                         Five Stars   \n",
       "3                                         Five Stars   \n",
       "4        I think's great. The cord length is perfect   \n",
       "\n",
       "                                         review_body review_date  \\\n",
       "0                                       Works great!   8/31/2015   \n",
       "1  This dries my hair faster that bigger, more po...   8/31/2015   \n",
       "2                                   Love this dryer!   8/31/2015   \n",
       "3                              styling hair in style   8/31/2015   \n",
       "4  I just got this last week. I think's great. Th...   8/31/2015   \n",
       "\n",
       "                                        preprocessed  \n",
       "0                                        works great  \n",
       "1  dry hair faster big powerful model love travel...  \n",
       "2                                         love dryer  \n",
       "3                                   style hair style  \n",
       "4      get last week think great cord length perfect  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pattern = r\"\\&\\#[0-9]+\\;\"\n",
    "\n",
    "df[\"preprocessed\"] = df[\"review_body\"].str.replace(pat=pattern, repl=\"\", regex=True)\n",
    "\n",
    "df[\"preprocessed\"] = df[\"preprocessed\"].apply(lambda row: lemmatize_doc(row))\n",
    "df[\"preprocessed\"] = df[\"preprocessed\"].apply(remove_accent)\n",
    "\n",
    "pattern = r\"[^\\w\\s]\"\n",
    "\n",
    "df[\"preprocessed\"] = df[\"preprocessed\"].str.replace(pat=pattern, repl=\" \", regex=True)\n",
    "\n",
    "df[\"preprocessed\"] = df[\"preprocessed\"].str.lower()\n",
    "\n",
    "df[\"preprocessed\"] = df[\"preprocessed\"].apply(remove_stop_words)\n",
    "\n",
    "pattern = r\"[\\s]+\"\n",
    "df[\"preprocessed\"] = df[\"preprocessed\"].str.replace(pat=pattern, repl=\" \", regex=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11470\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_count = []\n",
    "for i in range(len(specific_descriptor)):\n",
    "    sd_count.append(list())\n",
    "    for star in range(1, 6):\n",
    "        star_count = []\n",
    "        df_star = df[df['star_rating'] == star]\n",
    "        corpora = df_star[\"preprocessed\"].values\n",
    "        \n",
    "        tokenized = [corpus.split(\" \") for corpus in corpora]\n",
    "        count = 0\n",
    "        for review in tokenized:\n",
    "            for word in review:\n",
    "                if specific_descriptor[i] in word:\n",
    "                    count = count + 1\n",
    "                    continue\n",
    "                \n",
    "        sd_count[i].append([star, count, len(df_star), count / len(df_star)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 1, 1032, 0.0009689922480620155],\n",
       "  [2, 8, 639, 0.012519561815336464],\n",
       "  [3, 4, 999, 0.004004004004004004],\n",
       "  [4, 19, 2096, 0.009064885496183206],\n",
       "  [5, 125, 6704, 0.01864558472553699]],\n",
       " [[1, 0, 1032, 0.0],\n",
       "  [2, 0, 639, 0.0],\n",
       "  [3, 0, 999, 0.0],\n",
       "  [4, 0, 2096, 0.0],\n",
       "  [5, 10, 6704, 0.0014916467780429594]],\n",
       " [[1, 0, 1032, 0.0],\n",
       "  [2, 0, 639, 0.0],\n",
       "  [3, 0, 999, 0.0],\n",
       "  [4, 0, 2096, 0.0],\n",
       "  [5, 1, 6704, 0.00014916467780429595]],\n",
       " [[1, 15, 1032, 0.014534883720930232],\n",
       "  [2, 17, 639, 0.026604068857589983],\n",
       "  [3, 25, 999, 0.025025025025025027],\n",
       "  [4, 114, 2096, 0.05438931297709924],\n",
       "  [5, 583, 6704, 0.08696300715990453]],\n",
       " [[1, 0, 1032, 0.0],\n",
       "  [2, 0, 639, 0.0],\n",
       "  [3, 0, 999, 0.0],\n",
       "  [4, 1, 2096, 0.00047709923664122136],\n",
       "  [5, 1, 6704, 0.00014916467780429595]],\n",
       " [[1, 2, 1032, 0.001937984496124031],\n",
       "  [2, 0, 639, 0.0],\n",
       "  [3, 0, 999, 0.0],\n",
       "  [4, 0, 2096, 0.0],\n",
       "  [5, 2, 6704, 0.0002983293556085919]],\n",
       " [[1, 11, 1032, 0.01065891472868217],\n",
       "  [2, 12, 639, 0.018779342723004695],\n",
       "  [3, 26, 999, 0.026026026026026026],\n",
       "  [4, 29, 2096, 0.01383587786259542],\n",
       "  [5, 101, 6704, 0.01506563245823389]],\n",
       " [[1, 2, 1032, 0.001937984496124031],\n",
       "  [2, 0, 639, 0.0],\n",
       "  [3, 0, 999, 0.0],\n",
       "  [4, 2, 2096, 0.0009541984732824427],\n",
       "  [5, 12, 6704, 0.0017899761336515514]],\n",
       " [[1, 0, 1032, 0.0],\n",
       "  [2, 0, 639, 0.0],\n",
       "  [3, 0, 999, 0.0],\n",
       "  [4, 0, 2096, 0.0],\n",
       "  [5, 1, 6704, 0.00014916467780429595]],\n",
       " [[1, 7, 1032, 0.006782945736434108],\n",
       "  [2, 2, 639, 0.003129890453834116],\n",
       "  [3, 5, 999, 0.005005005005005005],\n",
       "  [4, 49, 2096, 0.023377862595419848],\n",
       "  [5, 292, 6704, 0.04355608591885442]],\n",
       " [[1, 0, 1032, 0.0],\n",
       "  [2, 0, 639, 0.0],\n",
       "  [3, 0, 999, 0.0],\n",
       "  [4, 0, 2096, 0.0],\n",
       "  [5, 1, 6704, 0.00014916467780429595]],\n",
       " [[1, 4, 1032, 0.003875968992248062],\n",
       "  [2, 1, 639, 0.001564945226917058],\n",
       "  [3, 10, 999, 0.01001001001001001],\n",
       "  [4, 23, 2096, 0.01097328244274809],\n",
       "  [5, 170, 6704, 0.02535799522673031]],\n",
       " [[1, 12, 1032, 0.011627906976744186],\n",
       "  [2, 3, 639, 0.004694835680751174],\n",
       "  [3, 3, 999, 0.003003003003003003],\n",
       "  [4, 2, 2096, 0.0009541984732824427],\n",
       "  [5, 2, 6704, 0.0002983293556085919]],\n",
       " [[1, 0, 1032, 0.0],\n",
       "  [2, 0, 639, 0.0],\n",
       "  [3, 1, 999, 0.001001001001001001],\n",
       "  [4, 0, 2096, 0.0],\n",
       "  [5, 1, 6704, 0.00014916467780429595]],\n",
       " [[1, 17, 1032, 0.016472868217054265],\n",
       "  [2, 8, 639, 0.012519561815336464],\n",
       "  [3, 7, 999, 0.007007007007007007],\n",
       "  [4, 7, 2096, 0.0033396946564885495],\n",
       "  [5, 5, 6704, 0.0007458233890214797]],\n",
       " [[1, 1, 1032, 0.0009689922480620155],\n",
       "  [2, 2, 639, 0.003129890453834116],\n",
       "  [3, 3, 999, 0.003003003003003003],\n",
       "  [4, 2, 2096, 0.0009541984732824427],\n",
       "  [5, 4, 6704, 0.0005966587112171838]],\n",
       " [[1, 0, 1032, 0.0],\n",
       "  [2, 0, 639, 0.0],\n",
       "  [3, 0, 999, 0.0],\n",
       "  [4, 0, 2096, 0.0],\n",
       "  [5, 1, 6704, 0.00014916467780429595]],\n",
       " [[1, 0, 1032, 0.0],\n",
       "  [2, 2, 639, 0.003129890453834116],\n",
       "  [3, 0, 999, 0.0],\n",
       "  [4, 0, 2096, 0.0],\n",
       "  [5, 1, 6704, 0.00014916467780429595]],\n",
       " [[1, 2, 1032, 0.001937984496124031],\n",
       "  [2, 0, 639, 0.0],\n",
       "  [3, 1, 999, 0.001001001001001001],\n",
       "  [4, 1, 2096, 0.00047709923664122136],\n",
       "  [5, 1, 6704, 0.00014916467780429595]],\n",
       " [[1, 30, 1032, 0.029069767441860465],\n",
       "  [2, 11, 639, 0.017214397496087636],\n",
       "  [3, 7, 999, 0.007007007007007007],\n",
       "  [4, 13, 2096, 0.006202290076335878],\n",
       "  [5, 32, 6704, 0.00477326968973747]]]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
